{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e14d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.8f}'.format\n",
    "import os\n",
    "import time\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "import collections\n",
    "from typing import Iterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a944cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class shockwave(object):\n",
    "    \"shockwave is represented by the initial point and slop\"\n",
    "    \"initial point includes the coordinates of time and location\"\n",
    "    \"initial point refers to the initial point of a shockwave within a square\"\n",
    "    \"the range of time is from 0 to the length of time interval\"\n",
    "    \"the location is from 0 to the length of the road section\"\n",
    "    \n",
    "    def __init__(self, s1, s2, ini_t, x, t_e):\n",
    "        \"s1 is the traffic state of the upstream traffic state and s2 is the downstream one\"\n",
    "        \"ini_t is the start time of this shockwave, x is the start position of this shockwave\"\n",
    "        \"t_e is the end time of this interval\"\n",
    "        self.uk = s1[0] # upstream traffic density\n",
    "        self.dk = s2[0] # downstream traffic density\n",
    "        self.uq = s1[1] # upstream flow\n",
    "        self.dq = s2[1] # downstream flow\n",
    "        if self.uq == self.dq or self.uk == self.dk:\n",
    "            self.slope = 1 / 10000000000000000000000000000\n",
    "\n",
    "        else:\n",
    "            self.slope = (self.uq - self.dq) / (self.uk - self.dk) # shockwave slope\n",
    "        self.ini_t = ini_t # initial coordinate on time axis\n",
    "        self.ini_x = x # initial coordinate on space axis\n",
    "        self.end_t = t_e # the end coordinate on time axis\n",
    "        self.end_x = self.ini_x + (self.end_t - self.ini_t) * self.slope # the end coordinate on space axis\n",
    "\n",
    "    def spatialLocation (t): # to calculate the position of the shockwave given a time\n",
    "        return (self.ini_x + (t - self.ini_t) * self.slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e04018f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to calculate the slope of the shockwave between two neighboring traffic states.\n",
    "def sw_slope(s1, s2): # s1 and s1 are in the form of [k, q]\n",
    "    slope = (s1[1] - s2[1]) / (s1[0] - s2[0])\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f7e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To indicate the properties of shockwaves\n",
    "def shockwave_property (sw): # to print the properties of a shockwave, the input of which is a shockwave object.\n",
    "    print ('up state = ', [sw.uk, sw.uq])\n",
    "    print ('down state = ', [sw.dk, sw.dq])\n",
    "    print ('slope = ', sw.slope)\n",
    "    print ('initial point = ', [sw.ini_t, sw.ini_x])\n",
    "    print ('end point = ', [sw.end_t, sw.end_x])\n",
    "\n",
    "def sw_List_property (swl): # to print the properties of a shockwave, the input of which is a list of shockwave object.\n",
    "    for i in swl:\n",
    "        print ('the properties of a shockwave:')\n",
    "        shockwave_property (i)\n",
    "        print ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12281c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Modifying this function'\n",
    "# This function is to convert the traffic state list and their boundaries positions to a list of shockwaves in the form of object,\n",
    "# and to convert the traffic state list and their boundaries positions to a list of state propagating into the space in list\n",
    "###############\n",
    "# The initialization can generate the shockwave list including the boundary conditions induced ones\n",
    "# The initialization can also generate the traffic state list on this road section starting from the generation the shockwave list \n",
    "###############\n",
    "\n",
    "def Initialization (us, ds, s, swp, t_0, t_e, L): # the output of this function is a list of shockwaves which is in the form of object.\n",
    "    \"us is the upstream boundary condition, which is in the form of [k, q]\"\n",
    "    \"ds is the downstream boundary condition, which is in the form of [k, q]\"\n",
    "    \"s is the list of traffic state on the road at the start of a sub-interval, the entry of which is in the form of [k, q]\"\n",
    "    \"swp is the list of shockwave position on the road at t_0, the entry of which is the position of the boundary between two neighboring states\"\n",
    "    \"t_0 is the start point of this sub time interval, which may be the start of this time interval\"\n",
    "    \"t_e is the end point of this time interval\"\n",
    "    \"L is the length of this road section\"\n",
    "    swl = []\n",
    "    sl = s\n",
    "    if len (s) <= 0:\n",
    "        print ('There is no traffic state. Please input it!')\n",
    "\n",
    "    elif len (s) == 1:\n",
    "        if s[0][0] == us[0] == ds[0]:\n",
    "            swl = []\n",
    "        if s[0][0] != us[0]:\n",
    "            slope_u = (s[0][1] - us[1])/(s[0][0] - us[0])\n",
    "            if slope_u > 0:\n",
    "                sw_u = shockwave(us, s[0], t_0, 0, t_e)\n",
    "                swl.append(sw_u)\n",
    "                sl = [us] + sl\n",
    "                \n",
    "    else:\n",
    "        if s[0][0] != us[0]:\n",
    "            slope_u = (s[0][1] - us[1])/(s[0][0] - us[0])\n",
    "            \n",
    "            if slope_u > 0:\n",
    "                sw_u = shockwave(us, s[0], t_0, 0, t_e)\n",
    "                swl.append(sw_u)\n",
    "                sl = [us] + sl\n",
    "\n",
    "        if len (s) > 1:\n",
    "            for i in range (len(s) - 1):\n",
    "                swl.append(shockwave(s[i], s[i+1], t_0, swp[i], t_e))\n",
    "\n",
    "        if s[-1][0] != ds[0]:\n",
    "            slope_d = (s[-1][1] - ds[1])/(s[-1][0] - ds[0])\n",
    "            \n",
    "            if slope_d < 0:\n",
    "                ini_d = [t_0, L]\n",
    "                sw_d = shockwave(s[-1], ds, t_0, L, t_e)\n",
    "                swl.append(sw_d) \n",
    "                sl = sl + [ds]\n",
    "    slops = slop_generation (swl) # the slops of all the shockwaves\n",
    "    start_points = sw_startPosition_generation (swl) # the start points of all the shockwaves\n",
    "    return swl, sl, slops, start_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082706eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are to list out the shockwave slopes, start positions, end posiitons, and states in the shockwave list\n",
    "def slop_generation (swl): # The input is the list of shockwave.\n",
    "    if len(swl) <= 0:\n",
    "        #print ('There is no shockwave.')\n",
    "        slope = []\n",
    "        \n",
    "    if len(swl) > 0:\n",
    "        slope = []\n",
    "        for i in swl:\n",
    "            slope.append (i.slope)\n",
    "    return slope\n",
    "\n",
    "def sw_startPosition_generation (swl): # The input is the list of shockwave.\n",
    "    iniP = []\n",
    "        # print ('There is no shockwave.')\n",
    "    if len(swl) > 0:\n",
    "        iniP = []\n",
    "        for i in swl:\n",
    "            iniP.append (i.ini_x)\n",
    "    return iniP\n",
    "\n",
    "def sw_endPosition_generation (swl): # The input is the list of shockwave.\n",
    "    endP = []\n",
    "    # if len(swl) <= 0:\n",
    "    #     print ('There is no shockwave.')\n",
    "        \n",
    "    if len(swl) > 0:\n",
    "        \n",
    "        for i in swl:\n",
    "            endP.append (i.end_x)\n",
    "        endP=sorted(endP)\n",
    "    return endP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228cbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate the intersection of two shockwaves\n",
    "def intersection(s1, s2):\n",
    "    int_t = (s1.slope * s1.ini_t - s2.slope * s2.ini_t + s2.ini_x - s1.ini_x) / (s1.slope - s2.slope)\n",
    "    int_x = s1.slope * (int_t - s1.ini_t) + s1.ini_x\n",
    "    inter_coor = [int_t, int_x] # the coordinates of the intersection\n",
    "    return inter_coor\n",
    "# to identify if this is in this square\n",
    "\n",
    "# the intersection between a shockwave and a spatial boundary\n",
    "def bdInsc (sw, t_0, t_e, L): \n",
    "    if sw.slope == 0:\n",
    "        print ('slope is zero')\n",
    "    else:\n",
    "        if sw.slope < 0:\n",
    "            t = - sw.ini_x / sw.slope + sw.ini_t\n",
    "            p = [t, 0]\n",
    "        else:\n",
    "            t = (L - sw.ini_x) / sw.slope + sw.ini_t\n",
    "            p = [t, L]\n",
    "        return p\n",
    "        # print (\"slope is equal to 0\")\n",
    "\n",
    "def intrsctPositionIdentify (inter_coor, t_0, t_e, L):\n",
    "    if t_e >= inter_coor[0] >= t_0:\n",
    "        if inter_coor[1] >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdaa55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the earliest intersection\n",
    "def earlistIntersection(swl, t_0, t_e, L):\n",
    "    intsc = [] # the index of shockwave and intersection position\n",
    "    min_t = t_e # the earliest intersection time\n",
    "    min_index = -4 # the initialized value for the index of the minimum shockwave, -4 refers to an initial index which is not found.\n",
    "    position = [-1, -1]  # the initialized value for the index of the minimum shockwave\n",
    "    if len(swl) > 0:\n",
    "        if len(swl) == 1:\n",
    "            p = bdInsc(swl[0], t_0, t_e, L) # the intersection between the shockwave and a boundary\n",
    "            if intrsctPositionIdentify (p, t_0, t_e, L):\n",
    "                if swl[0].slope < 0:\n",
    "                    min_index = -3.3 # backward shockwave\n",
    "\n",
    "                else:\n",
    "                    min_index = -3.7 # forward shockwave\n",
    "                # min_index = -3 # -3 refers to that there is only one shockwave, which will intersect a boundary within the current interval\n",
    "                position = p\n",
    "        else:\n",
    "            if swl[0].slope < 0:\n",
    "                p = bdInsc(swl[0], t_0, t_e, L)\n",
    "                if intrsctPositionIdentify (p, t_0, t_e, L):\n",
    "                    if p[0] < min_t:\n",
    "                        min_t = p[0]\n",
    "                        min_index = -1 # -1 refers to that the first shockwave will intersect the upstream boundary\n",
    "                        position = p\n",
    "            if swl[-1].slope > 0:\n",
    "                p = bdInsc(swl[-1], t_0, t_e, L)\n",
    "                if intrsctPositionIdentify (p, t_0, t_e, L):\n",
    "                    if p[0] < min_t:\n",
    "                        min_t = p[0]\n",
    "                        min_index = -2 # -2 refers to the last shockwave will intersect the downstream boundary\n",
    "                        position = p\n",
    "            for i in range(len(swl)-1):\n",
    "                if swl[i].slope > swl[i+1].slope:\n",
    "                    p = intersection (swl[i], swl[i+1]) # position is the positioin of intersection\n",
    "                    if intrsctPositionIdentify (p, t_0, t_e, L):\n",
    "                        if p[0] < min_t:\n",
    "                            min_t = p[0]\n",
    "                            min_index = i # the intersection between the ith shockwave and the i+1th shockwave\n",
    "                            position = p\n",
    "    return [min_index, position] # the first is the index of the minmum one and the second one is its coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be8c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to generate state list on the road at the earliest intersection\n",
    "# This function builds up the relationship between the state list within a sub-interval and that at the time of the earlist intersection.\n",
    "def state_update (earlistIntersection, sl): # sl is the traffic states within a sub interval\n",
    "    # s is the traffic state at the time of the earliest intersection\n",
    "    if len(sl) > 1:\n",
    "        if earlistIntersection[0] == -3.3: # just one backward shockwave on the temporal-spatial area\n",
    "            s = [sl[-1]]\n",
    "        elif earlistIntersection[0] == -3.7: # just one forward shockwave on the temporal-spatial area\n",
    "            s = [sl[0]]\n",
    "    \n",
    "        elif earlistIntersection[0] == -2: #-2 refers to the last shockwave will intersect the downstream boundary\n",
    "            s = sl[:len(sl)-1]   #maybe have bug\n",
    "            \n",
    "        elif earlistIntersection[0] == -1: # -1 refers to that the first shockwave will intersect the upstream boundary\n",
    "            s = sl[1:]\n",
    "        else:\n",
    "            min_index = earlistIntersection[0]\n",
    "            s = sl[:min_index + 1] + sl[min_index + 2:]\n",
    "\n",
    "    else:\n",
    "        s = sl\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "007fe922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to generate the shockwave position at the end of a sub interval\n",
    "# This function builds up the relationship between the shockwave list within a sub-interval and that at the time of the earlist intersection.\n",
    "def swp_update (earlistIntersection, swl): #swl is the shockwave list within a sub-interval\n",
    "    swp = []\n",
    "    # print (earlistIntersection[0])\n",
    "    if len(swl) > 0:\n",
    "        t_e = earlistIntersection[1][0] # earlistIntersection[1][0] is the time of earliest intersection\n",
    "        if -4 < earlistIntersection[0] < -3: # There is only one shockwave in the shockwave list\n",
    "            swp = []\n",
    "        elif earlistIntersection[0] == -2:\n",
    "            \"drop the last shockwave and keep the others\"\n",
    "            \n",
    "            sw_Lst = swl[:len(swl)-1]\n",
    "            for i in sw_Lst:\n",
    "                swp.append(i.ini_x + (t_e - i.ini_t) * i.slope) \n",
    "        elif earlistIntersection[0] == -1:\n",
    "            sw_Lst = swl[1:]\n",
    "            for i in sw_Lst:\n",
    "                swp.append(i.ini_x + (t_e - i.ini_t) * i.slope) \n",
    "        else:\n",
    "            min_index = earlistIntersection[0]\n",
    "            for i in swl[:min_index]:\n",
    "                swp.append(i.ini_x + (t_e - i.ini_t) * i.slope) \n",
    "            for i in swl[min_index + 1:]:\n",
    "                swp.append(i.ini_x + (t_e - i.ini_t) * i.slope)\n",
    "                \n",
    "            swp=sorted(swp)  # maybe need debug\n",
    "\n",
    "    return swp   # maybe also need to return sw_Lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c60c1ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to generate the final result of a shockwave graph in an interval\n",
    "def swg1 (us, ds, s, swp, t_0, t_e, L):\n",
    "    \"s is he initial state at the start of an interval\"\n",
    "    \"swp is the initial shockwave positions at the start of an interval\"\n",
    "    s_ini = s\n",
    "    t_ini = t_0\n",
    "    State = [] # The list of traffic state at every sub-interval, the entry of which is a list of state.\n",
    "    State_ini = [] # the initial state\n",
    "    ShockwavePosition = [] # The list of shockwave start positions at every sub-interval, the entry of which is a list of positions.\n",
    "    Slopes = [] # The list of the slopes of all shockwave at every sub-interval.\n",
    "    TS = [] #The time series of sub-interval\n",
    "    Inter_P=[] # store the intersection point of shockwaves within the interval \n",
    "    EarlyIndex = -5 # To activate this recusion to show that it is not equal to -4\n",
    "    count=0\n",
    "    while EarlyIndex != -4:\n",
    "        sw_Lst, s_Lst, slp_Lst, swp_Lst = Initialization (us, ds, s_ini, swp, t_ini, t_e, L)\n",
    "        count=count+1\n",
    "        print(\"debug:\",count)\n",
    "        \"sw_Lst is the shockwave list\"\n",
    "        \"s_Lst is the state list\"\n",
    "        \"slp_Lst is the slope list\"\n",
    "        \"swp_Lst is the shockwave start position list\"\n",
    "        # To generate the list of shockwave slopes.\n",
    "        # slps = slop_generation (sw_List) # The slopes of all the shockwaves\n",
    "        # for i in sw_List:\n",
    "        #     slps.append(i.slope)\n",
    "        Slopes.append(slp_Lst)\n",
    "        #swp = sw_startPosition_generation (swl) # The start points of all the shockwaves\n",
    "        ShockwavePosition.append(swp_Lst)\n",
    "        TS.append(t_ini)\n",
    "        insc = earlistIntersection(sw_Lst, t_ini, t_e, L)\n",
    "        # print ('insc = ', insc)\n",
    "        EarlyIndex = insc[0]\n",
    "        #print (EarlyIndex)\n",
    "        State.append(s_Lst)\n",
    "        # ite = 1\n",
    "        # print ('ite = ', ite)\n",
    "        if EarlyIndex != -4:\n",
    "            # ite += 1\n",
    "            s_ini = state_update (insc, s_Lst)\n",
    "            swp = swp_update (insc, sw_Lst)\n",
    "            t_ini = insc[1][0]   # the time of earliest intersection.\n",
    "            Inter_P.append(insc[1])\n",
    "            #print(\"intersections within the interval\", insc[1])\n",
    "            # ShockwavePosition.append(swp) # the positions of shockwaves at earliest intersection.\n",
    "            \n",
    "        else: \n",
    "            \"This needs to debug.XxxxxXXXXXXXX\"   \n",
    "            sw_endP = sw_endPosition_generation (sw_Lst)  # final sw (in the latest subinterval) end points\n",
    "            s_endP = State[-1] # final state list in the latest subinterval \n",
    "            TS.append(t_e)\n",
    "\n",
    "    return State, ShockwavePosition, Slopes, TS, sw_Lst, sw_endP, s_endP, Inter_P  # sw_Lst is the final shockwave list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84632624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_SWL_final(ShockwavePosition,TS, Inter_P, sw_endP, Slopes, State, L):\n",
    "    # Define the column names\n",
    "    column_names = ['ini_t', 'ini_x', 'end_t','end_x','slope','uk','uq','dk','dq']  # Add or replace with your column names\n",
    "    # Create an empty DataFrame with these column names\n",
    "    SWL_revised= pd.DataFrame(np.zeros((sum(len(sublist) for sublist in ShockwavePosition), len(column_names))),columns=column_names)\n",
    "    SWL_revised['ini_x'] = [item for sublist in ShockwavePosition for item in sublist]\n",
    "    SWL_revised['ini_t'] = [TS[i] for i in range(len(ShockwavePosition)) for _ in range(len(ShockwavePosition[i]))]\n",
    "    Shockwave_endPositionx=[]\n",
    "    for i in range(1,len(ShockwavePosition)):\n",
    "        if (Inter_P[i-1][1]==L or Inter_P[i-1][1]==0) and (len(ShockwavePosition[i-1])==len(ShockwavePosition[i])):\n",
    "            Shockwave_endPositionx.append(sorted(ShockwavePosition[i]))\n",
    "        else:\n",
    "            Shockwave_endPositionx.append(sorted(ShockwavePosition[i]+[Inter_P[i-1][1]]))\n",
    "    Shockwave_endPositionx.append(sw_endP)\n",
    "    SWL_revised['end_x']= [item for sublist in Shockwave_endPositionx for item in sublist]\n",
    "    SWL_revised['end_t'] = [TS[i+1] for i in range(len(ShockwavePosition)) for _ in range(len(ShockwavePosition[i]))]\n",
    "    SWL_revised['slope'] = [item for sublist in Slopes for item in sublist]\n",
    "    SWL_revised['uk'] = [item[0] for sublist in State for item in sublist[:-1]]\n",
    "    SWL_revised['uq'] = [item[1] for sublist in State for item in sublist[:-1]]\n",
    "    SWL_revised['dk'] = [item[0] for sublist in State for item in sublist[1:]]\n",
    "    SWL_revised['dq'] = [item[1] for sublist in State for item in sublist[1:]]\n",
    "    \n",
    "    rows_to_drop=[]\n",
    "    for i in range(len(SWL_revised)):\n",
    "        for j in range(1,len(SWL_revised)):\n",
    "            if SWL_revised['end_t'][i]==SWL_revised['ini_t'][j] and SWL_revised['end_x'][i]==SWL_revised['ini_x'][j] and SWL_revised['slope'][i]==SWL_revised['slope'][j]:\n",
    "                rows_to_drop.append(j)\n",
    "                SWL_revised.loc[i, 'end_t'] = SWL_revised.loc[j, 'end_t']\n",
    "                SWL_revised.loc[i, 'end_x'] = SWL_revised.loc[j, 'end_x']\n",
    "                \n",
    "    #print(rows_to_drop)\n",
    "    SWL_f=SWL_revised.drop(rows_to_drop)      \n",
    "    SWL_f=SWL_f.reset_index(drop=True)\n",
    "    \n",
    "    # Change elements in 'end_x' that are below 0 to 0\n",
    "    SWL_f.loc[SWL_f['end_x'] < 0, 'end_x'] = 0.001\n",
    "    SWL_f = SWL_f.round(8)\n",
    "    return SWL_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4839d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if a point is enclosed by a polygon (ture/false)\n",
    "def pnpoly(verts, x, y):\n",
    "    #check if x and/or y is iterable\n",
    "    xit, yit = isinstance(x, Iterable), isinstance(y, Iterable)\n",
    "    #if not iterable, make an iterable of length 1\n",
    "    X = x if xit else (x, )\n",
    "    Y = y if yit else (y, )\n",
    "    #store verts length as a range to juggle j\n",
    "    r = range(len(verts))\n",
    "    #final results if x or y is iterable\n",
    "    results = []\n",
    "    #traverse x and y coordinates\n",
    "    for xp in X:\n",
    "        for yp in Y:\n",
    "            c = 0 #reset c at every new position\n",
    "            for i in r:\n",
    "                j = r[i-1] #set j to position before i\n",
    "                #store a few arguments to shorten the if statement\n",
    "                yneq       = (verts[i][1] > yp) != (verts[j][1] > yp)\n",
    "                xofs, yofs = (verts[j][0] - verts[i][0]), (verts[j][1] - verts[i][1])\n",
    "                #if we have crossed a line, increment c\n",
    "                if (yneq and (xp < xofs * (yp - verts[i][1]) / yofs + verts[i][0])):\n",
    "                    c += 1\n",
    "            #if c is odd store the coordinates        \n",
    "            if c%2:\n",
    "                results.append((xp, yp))\n",
    "    #return either coordinates or a bool, depending if x or y was an iterable\n",
    "    return results if (xit or yit) else bool(c%2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5dd80",
   "metadata": {},
   "source": [
    "# example start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a86431f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: 1\n",
      "debug: 2\n",
      "debug: 3\n"
     ]
    }
   ],
   "source": [
    "t_0 = 0.00   # the unit is hour\n",
    "t_e = 0.01   # the unit is hour\n",
    "L = 1 # mile\n",
    "us = [40, 2400]\n",
    "ds = [150, 900]\n",
    "s_ini = [[50, 3000], [40, 2400], [30, 1800]]\n",
    "swp = [0.4, 0.7]  # the unit is mile\n",
    "State, ShockwavePosition, Slopes, TS, sw_Lst, sw_endP, s_endP, Inter_P= swg1 (us, ds, s_ini, swp, t_0, t_e, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1f17891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ini_t</th>\n",
       "      <th>ini_x</th>\n",
       "      <th>end_t</th>\n",
       "      <th>end_x</th>\n",
       "      <th>slope</th>\n",
       "      <th>uk</th>\n",
       "      <th>uq</th>\n",
       "      <th>dk</th>\n",
       "      <th>dq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.01000000</td>\n",
       "      <td>0.60000000</td>\n",
       "      <td>60.00000000</td>\n",
       "      <td>40</td>\n",
       "      <td>2400</td>\n",
       "      <td>50</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.40000000</td>\n",
       "      <td>0.00851852</td>\n",
       "      <td>0.91111111</td>\n",
       "      <td>60.00000000</td>\n",
       "      <td>50</td>\n",
       "      <td>3000</td>\n",
       "      <td>40</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.70000000</td>\n",
       "      <td>0.00444444</td>\n",
       "      <td>0.96666667</td>\n",
       "      <td>60.00000000</td>\n",
       "      <td>40</td>\n",
       "      <td>2400</td>\n",
       "      <td>30</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.00444444</td>\n",
       "      <td>0.96666667</td>\n",
       "      <td>-7.50000000</td>\n",
       "      <td>30</td>\n",
       "      <td>1800</td>\n",
       "      <td>150</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00444444</td>\n",
       "      <td>0.96666667</td>\n",
       "      <td>0.00851852</td>\n",
       "      <td>0.91111111</td>\n",
       "      <td>-13.63636364</td>\n",
       "      <td>40</td>\n",
       "      <td>2400</td>\n",
       "      <td>150</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00851852</td>\n",
       "      <td>0.91111111</td>\n",
       "      <td>0.01000000</td>\n",
       "      <td>0.88000000</td>\n",
       "      <td>-21.00000000</td>\n",
       "      <td>50</td>\n",
       "      <td>3000</td>\n",
       "      <td>150</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ini_t      ini_x      end_t      end_x        slope  uk    uq   dk  \\\n",
       "0 0.00000000 0.00000000 0.01000000 0.60000000  60.00000000  40  2400   50   \n",
       "1 0.00000000 0.40000000 0.00851852 0.91111111  60.00000000  50  3000   40   \n",
       "2 0.00000000 0.70000000 0.00444444 0.96666667  60.00000000  40  2400   30   \n",
       "3 0.00000000 1.00000000 0.00444444 0.96666667  -7.50000000  30  1800  150   \n",
       "4 0.00444444 0.96666667 0.00851852 0.91111111 -13.63636364  40  2400  150   \n",
       "5 0.00851852 0.91111111 0.01000000 0.88000000 -21.00000000  50  3000  150   \n",
       "\n",
       "     dq  \n",
       "0  3000  \n",
       "1  2400  \n",
       "2  1800  \n",
       "3   900  \n",
       "4   900  \n",
       "5   900  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.options.mode.copy_on_write = True \n",
    "SWL_f=gen_SWL_final(ShockwavePosition,TS, Inter_P, sw_endP, Slopes, State, L)\n",
    "SWL_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ba25e",
   "metadata": {},
   "source": [
    "# example test end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d3169fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0),\n",
       " (0.0, 1),\n",
       " (0.01, 1),\n",
       " (0.01, 0),\n",
       " (0.01, 0.6),\n",
       " (0.0, 0.4),\n",
       " (0.00851852, 0.91111111),\n",
       " (0.0, 0.7),\n",
       " (0.00444444, 0.96666667),\n",
       " (0.01, 0.88)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_nodes(t_0,t_e,L,SWL_df):\n",
    "    nodes=[]\n",
    "    nodes.append((t_0,0))  # change for different time\n",
    "    nodes.append((t_0,L))  # change\n",
    "    nodes.append((t_e,L))  # change\n",
    "    nodes.append((t_e,0))  # change\n",
    "    for i in range(len(SWL_df)):\n",
    "        nodes.append((SWL_df.iloc[i]['ini_t'],SWL_df.iloc[i]['ini_x']))\n",
    "        nodes.append((SWL_df.iloc[i]['end_t'],SWL_df.iloc[i]['end_x']))\n",
    "    nodes= list(dict.fromkeys(nodes)) #remove duplicates from a list while preserving the order of elements. \n",
    "    return nodes\n",
    "nodes=get_nodes(t_0,t_e,L,SWL_f)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2fe8afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 4],\n",
       " [5, 6],\n",
       " [7, 8],\n",
       " [1, 8],\n",
       " [8, 6],\n",
       " [6, 9],\n",
       " [0, 5],\n",
       " [5, 7],\n",
       " [7, 1],\n",
       " [1, 2],\n",
       " [3, 4],\n",
       " [4, 9],\n",
       " [9, 2],\n",
       " [0, 3]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_edges(t_0,t_e,L,SWL_df,nodes):\n",
    "    edges=[]\n",
    "    # within diagram edges\n",
    "    for i in range(len(SWL_df)):\n",
    "        Edge=[]\n",
    "        s_p=(SWL_df.iloc[i]['ini_t'],SWL_df.iloc[i]['ini_x'])\n",
    "        e_p=(SWL_df.iloc[i]['end_t'],SWL_df.iloc[i]['end_x'])\n",
    "        Edge.append(nodes.index(s_p))\n",
    "        Edge.append(nodes.index(e_p))\n",
    "        edges.append(Edge)\n",
    "    # edges on diagram boundaries\n",
    "    nodes_lb=[]\n",
    "    nodes_ub=[]\n",
    "    nodes_rb=[]\n",
    "    nodes_bb=[]\n",
    "    for i in range(len(nodes)):\n",
    "        if nodes[i][0]==t_0:  # t_0 should be change to different time\n",
    "            nodes_lb.append(nodes[i])\n",
    "        if nodes[i][1]==L:  # L should be change to different link length\n",
    "            nodes_ub.append(nodes[i])\n",
    "        if nodes[i][0]==t_e:  # t_e should be change to different time\n",
    "            nodes_rb.append(nodes[i])\n",
    "        if nodes[i][1]==0:  # 0 s\n",
    "            nodes_bb.append(nodes[i])\n",
    "\n",
    "    nodes_lb=sorted(nodes_lb)   \n",
    "    nodes_ub=sorted(nodes_ub)   \n",
    "    nodes_rb=sorted(nodes_rb)   \n",
    "    nodes_bb=sorted(nodes_bb)  \n",
    "    \n",
    "    for i in range(len(nodes_lb)-1): # consecutive intersections make up an edge\n",
    "        Edge=[]\n",
    "        Edge.append(nodes.index(nodes_lb[i])) \n",
    "        Edge.append(nodes.index(nodes_lb[i+1]))\n",
    "        edges.append(Edge)\n",
    "    for i in range(len(nodes_ub)-1): # consecutive intersections make up an edge\n",
    "        Edge=[]\n",
    "        Edge.append(nodes.index(nodes_ub[i])) \n",
    "        Edge.append(nodes.index(nodes_ub[i+1]))\n",
    "        edges.append(Edge)\n",
    "    for i in range(len(nodes_rb)-1): # consecutive intersections make up an edge\n",
    "        Edge=[]\n",
    "        Edge.append(nodes.index(nodes_rb[i])) \n",
    "        Edge.append(nodes.index(nodes_rb[i+1]))\n",
    "        edges.append(Edge)\n",
    "    for i in range(len(nodes_bb)-1): # consecutive intersections make up an edge\n",
    "        Edge=[]\n",
    "        Edge.append(nodes.index(nodes_bb[i])) \n",
    "        Edge.append(nodes.index(nodes_bb[i+1]))\n",
    "        edges.append(Edge)\n",
    "        \n",
    "    return edges\n",
    "\n",
    "edges=get_edges(t_0,t_e,L,SWL_f,nodes)\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a056950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3, 4],\n",
       " [0, 5, 6, 9, 4],\n",
       " [0, 5, 7, 8, 6, 9, 4],\n",
       " [0, 5, 7, 1, 8, 6, 9, 4],\n",
       " [0, 5, 7, 8, 1, 2, 9, 4],\n",
       " [0, 5, 6, 8, 1, 2, 9, 4],\n",
       " [0, 5, 6, 8, 7, 1, 2, 9, 4],\n",
       " [0, 5, 7, 1, 2, 9, 4],\n",
       " [0, 3, 4, 9, 2, 1, 7, 8, 6, 5],\n",
       " [0, 3, 4, 9, 2, 1, 8, 6, 5],\n",
       " [0, 3, 4, 9, 6, 5],\n",
       " [0, 3, 4, 9, 2, 1, 8, 7, 5],\n",
       " [0, 3, 4, 9, 6, 8, 7, 5],\n",
       " [0, 3, 4, 9, 6, 8, 1, 7, 5],\n",
       " [0, 3, 4, 9, 2, 1, 7, 5],\n",
       " [5, 7, 8, 6],\n",
       " [1, 8, 6, 5, 7],\n",
       " [1, 2, 9, 6, 5, 7, 8],\n",
       " [1, 2, 9, 6, 5, 7],\n",
       " [1, 7, 8, 6, 9, 2],\n",
       " [1, 8, 6, 9, 2],\n",
       " [1, 8, 7]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_cycles(edges):\n",
    "    cycles=[]\n",
    "    \n",
    "    \n",
    "    def findNewCycles(path,edges):\n",
    "        start_node = path[0]\n",
    "        next_node= None\n",
    "        sub = []\n",
    "\n",
    "        #visit each edge and each node of each edge\n",
    "        for edge in edges:\n",
    "            node1, node2 = edge\n",
    "            if start_node in edge:\n",
    "                    if node1 == start_node:\n",
    "                        next_node = node2\n",
    "                    else:\n",
    "                        next_node = node1\n",
    "                    if not visited(next_node, path):\n",
    "                            # neighbor node not on path yet\n",
    "                            sub = [next_node]\n",
    "                            sub.extend(path)\n",
    "                            # explore extended path\n",
    "                            findNewCycles(sub,edges);\n",
    "                    elif len(path) > 2  and next_node == path[-1]:\n",
    "                            # cycle found\n",
    "                            p = rotate_to_smallest(path);\n",
    "                            inv = invert(p)\n",
    "                            if isNew(p) and isNew(inv):\n",
    "                                cycles.append(p)\n",
    "\n",
    "    def invert(path):\n",
    "        return rotate_to_smallest(path[::-1])\n",
    "\n",
    "    #  rotate cycle path such that it begins with the smallest node\n",
    "    def rotate_to_smallest(path):\n",
    "        n = path.index(min(path))\n",
    "        return path[n:]+path[:n]\n",
    "\n",
    "    def isNew(path):\n",
    "        return not path in cycles\n",
    "\n",
    "    def visited(node, path):\n",
    "        return node in path\n",
    "    \n",
    "    \n",
    "    \n",
    "    for edge in edges:\n",
    "        for node in edge:\n",
    "            findNewCycles([node],edges)\n",
    "    for cy in cycles:\n",
    "        path = [str(node) for node in cy]\n",
    "        s = \",\".join(path)\n",
    "        #print(s)    \n",
    "        \n",
    "    return cycles\n",
    "\n",
    "\n",
    "cycles=generate_cycles(edges)\n",
    "cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17786cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mini cycles 5\n",
      "Polygon_new_update [[(0.0, 0), (0.01, 0), (0.01, 0.6)], [(0.0, 0), (0.0, 0.4), (0.00851852, 0.91111111), (0.01, 0.88), (0.01, 0.6)], [(0.0, 0.4), (0.0, 0.7), (0.00444444, 0.96666667), (0.00851852, 0.91111111)], [(0.0, 1), (0.00444444, 0.96666667), (0.00851852, 0.91111111), (0.01, 0.88), (0.01, 1)], [(0.0, 1), (0.00444444, 0.96666667), (0.0, 0.7)]]\n",
      "cycles_new_update [[0, 3, 4], [0, 5, 6, 9, 4], [5, 7, 8, 6], [1, 8, 6, 9, 2], [1, 8, 7]]\n"
     ]
    }
   ],
   "source": [
    "def minimal_cycle(cycles,nodes):\n",
    "    # avoid rewriting cycles list\n",
    "    cycles_temp=cycles.copy()\n",
    "    \n",
    "    Polygon = collections.defaultdict(list) # based on ALL cycles generate polygons\n",
    "    for i in range(len(cycles_temp)):\n",
    "        for j in cycles_temp[i]:\n",
    "            Polygon[i].append(nodes[j])\n",
    "            \n",
    "    # delete larger polygons which contains all nodes of smaller ones\n",
    "    for i in range(len(cycles_temp)):\n",
    "        cycle1_edge=[]\n",
    "        for k in range(len(cycles_temp[i])-1): #i is the shorter cycle\n",
    "            cycle1_edge.append([cycles_temp[i][k],cycles_temp[i][k+1]]) # e.g. cycle 0: 0,1,13,15 cycle_edge=[[0,1],[1,0],[1,13],[31,1],[13,15],[15,13],[15,0],[0,15]]\n",
    "            cycle1_edge.append([cycles_temp[i][k+1],cycles_temp[i][k]])\n",
    "        cycle1_edge.append([cycles_temp[i][0],cycles_temp[i][-1]])\n",
    "        cycle1_edge.append([cycles_temp[i][-1],cycles_temp[i][0]])\n",
    "        for j in range(len(cycles_temp)):\n",
    "            if i!=j:\n",
    "                check =  all(item in cycles_temp[j] for item in cycles_temp[i]) # check==true, if the set of vertecies of cycles j contain all vertecies of cycle i\n",
    "                if ((check==True)&(len(cycles_temp[j])>1)&(len(cycles_temp[i])>1)):\n",
    "                    cycle2_edge=[]\n",
    "                    for kk in range(len(cycles_temp[j])-1): #j is the longer cycle\n",
    "                        cycle2_edge.append([cycles_temp[j][kk],cycles_temp[j][kk+1]])\n",
    "                        cycle2_edge.append([cycles_temp[j][kk+1],cycles_temp[j][kk]])\n",
    "                    cycle2_edge.append([cycles_temp[j][0],cycles_temp[j][-1]])\n",
    "                    cycle2_edge.append([cycles_temp[j][-1],cycles_temp[j][0]])\n",
    "                    for h in range(len(cycle1_edge)):\n",
    "                        if cycle1_edge[h] not in cycle2_edge: # find the edge of cycle i not belong to the set of edge of cycle j\n",
    "                            #print(i,j,cycle1_edge[h])\n",
    "                            break\n",
    "                    med_x=(nodes[cycle1_edge[h][0]][0]+nodes[cycle1_edge[h][1]][0])/2\n",
    "                    med_y=(nodes[cycle1_edge[h][0]][1]+nodes[cycle1_edge[h][1]][1])/2 #medium coordination of that edge\n",
    "                    #print(med_x,med_y)\n",
    "                    indexx=pnpoly(Polygon[j],med_x,med_y)# True: cycle j contains cycle i\n",
    "                    #print(indexx)\n",
    "                    if indexx==True: \n",
    "                        cycles_temp[j]=['ha']\n",
    "\n",
    "    cycles_new=[]\n",
    "    for i in range(len(cycles_temp)):\n",
    "        if cycles_temp[i]!=['ha']:\n",
    "            cycles_new.append(cycles_temp[i])\n",
    "    \n",
    "    Polygon_new = collections.defaultdict(list)\n",
    "    for i in range(len(cycles_new)):\n",
    "        for j in cycles_new[i]:\n",
    "            Polygon_new[i].append(nodes[j])\n",
    "\n",
    "    # delete larger polygons only contain partial nodes of minimal polygons        \n",
    "    nodes_all=list(range(0,len(nodes))) \n",
    "    for i in range(len(Polygon_new)):\n",
    "        Nodes_not=[x for x in nodes_all if x not in cycles_new[i]]\n",
    "        for j in Nodes_not:\n",
    "            index=pnpoly(Polygon_new[i],nodes[j][0],nodes[j][1])\n",
    "            if index==True:\n",
    "                Polygon_new.pop(i)\n",
    "\n",
    "    Polygon_new_update = []\n",
    "    cycles_new_update=[]\n",
    "    for i in range(len(cycles_new)):\n",
    "        if len(Polygon_new[i])!=0:\n",
    "            Polygon_new_update.append(Polygon_new[i])\n",
    "            cycles_new_update.append(cycles_new[i])\n",
    "    print(\"number of mini cycles\",len(cycles_new_update))        \n",
    "    return Polygon_new_update, cycles_new_update\n",
    "\n",
    "Polygon_new_update, cycles_new_update= minimal_cycle(cycles, nodes)\n",
    "print(\"Polygon_new_update\",Polygon_new_update)\n",
    "print(\"cycles_new_update\",cycles_new_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f044b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_clockwise(vertices):\n",
    "    \"\"\"\n",
    "    :param vertices: A list of tuples/lists representing the x, y coordinates of vertices.\n",
    "    :return: True: counter-clockwise, False: clockwise\n",
    "    \"\"\"\n",
    "    sum = 0\n",
    "    for i in range(len(vertices)):\n",
    "        # Get the current and next vertex indices\n",
    "        j = (i + 1) % len(vertices)\n",
    "        \n",
    "        # Compute the area of the trapezoid under current and next vertex\n",
    "        sum += (vertices[j][0] - vertices[i][0]) * (vertices[j][1] + vertices[i][1])\n",
    "    \n",
    "    # If sum is negative, points are in clockwise order\n",
    "    return sum < 0\n",
    "\n",
    "# Example usage\n",
    "#vertices = [(0,0), (1,0), (1,1), (0.5,0.5), (0,1)]  # Define the vertices of your cycle\n",
    "#vertices = [(0,0), (0,1), (0.5,0.5), (1,1), (1,0)]  # Define the vertices of your cycle\n",
    "#vertices = [(0, 0), (0.01, 0), (0.01, 0.6000000000000001)]\n",
    "#vertices =[(0, 1), (0.004444444444444445, 0.9666666666666667), (0.0, 0.7)]\n",
    "#vertices =[(0, 0), (0.0, 0.4), (0.008518518518518517, 0.9111111111111111), (0.01, 0.88), (0.01, 0.6000000000000001)] \n",
    "#vertices =[(0, 1), (0.004444444444444445, 0.9666666666666667), (0.008518518518518517, 0.9111111111111111), (0.01, 0.88), (0.01, 1)] \n",
    "#print(is_clockwise(vertices))  # True: counter-clockwise, False: clockwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41e2f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_clockwise(vertices):\n",
    "    ver_set=[]\n",
    "    ver_set.append(vertices[0])\n",
    "    for i in range(len(vertices)-1,0,-1):\n",
    "        ver_set.append(vertices[i])\n",
    "    return ver_set\n",
    "#vertices = [(0, 1), (0.004444444444444445, 0.9666666666666667), (0.008518518518518517, 0.9111111111111111), (0.01, 0.88), (0.01, 1)] \n",
    "#test=convert_to_clockwise(vertices)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdb1593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the first and second vertices's time are same\n",
    "def reorder_vertices(vertices):\n",
    "    # Find the index of the vertex that is earliest and highest\n",
    "    start_index = min(range(len(vertices)), key=lambda i: (vertices[i][0], -vertices[i][1]))\n",
    "\n",
    "    # Rearrange the list so that this vertex starts first and the order is maintained\n",
    "    reordered_vertices = vertices[start_index:] + vertices[:start_index]\n",
    "\n",
    "    return reordered_vertices\n",
    "\n",
    "#vertices = [(0.008518518518518517, 0.9111111111111111), (0.01, 0.88), (0.01, 0.6000000000000001), (0, 0), (0.0, 0.4)] \n",
    "#vertices = [(0.0, 0.4), (0.0, 0.7), (0.004444444444444445, 0.9666666666666667), (0.008518518518518517, 0.9111111111111111)]\n",
    "#test=reorder_vertices(vertices)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7882839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 2, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.01000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.01000000</td>\n",
       "      <td>0.88000000</td>\n",
       "      <td>0.00851852</td>\n",
       "      <td>0.91111111</td>\n",
       "      <td>0.00444444</td>\n",
       "      <td>0.96666667</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.00444444</td>\n",
       "      <td>0.96666667</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.70000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.70000000</td>\n",
       "      <td>0.00444444</td>\n",
       "      <td>0.96666667</td>\n",
       "      <td>0.00851852</td>\n",
       "      <td>0.91111111</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.40000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.40000000</td>\n",
       "      <td>0.00851852</td>\n",
       "      <td>0.91111111</td>\n",
       "      <td>0.01000000</td>\n",
       "      <td>0.88000000</td>\n",
       "      <td>0.01000000</td>\n",
       "      <td>0.60000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.01000000</td>\n",
       "      <td>0.60000000</td>\n",
       "      <td>0.01000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1           2           3           4           5   \\\n",
       "0  0.00000000  1.00000000  0.01000000  1.00000000  0.01000000  0.88000000   \n",
       "1  0.00000000  1.00000000  0.00444444  0.96666667  0.00000000  0.70000000   \n",
       "2  0.00000000  0.70000000  0.00444444  0.96666667  0.00851852  0.91111111   \n",
       "3  0.00000000  0.40000000  0.00851852  0.91111111  0.01000000  0.88000000   \n",
       "4  0.00000000  0.00000000  0.01000000  0.60000000  0.01000000  0.00000000   \n",
       "5 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000   \n",
       "6 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000   \n",
       "7 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000   \n",
       "\n",
       "           6           7           8           9           10          11  \\\n",
       "0  0.00851852  0.91111111  0.00444444  0.96666667 -1.00000000 -1.00000000   \n",
       "1 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000   \n",
       "2  0.00000000  0.40000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000   \n",
       "3  0.01000000  0.60000000  0.00000000  0.00000000 -1.00000000 -1.00000000   \n",
       "4 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000   \n",
       "5 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000   \n",
       "6 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000   \n",
       "7 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000   \n",
       "\n",
       "           12          13          14          15  \n",
       "0 -1.00000000 -1.00000000 -1.00000000 -1.00000000  \n",
       "1 -1.00000000 -1.00000000 -1.00000000 -1.00000000  \n",
       "2 -1.00000000 -1.00000000 -1.00000000 -1.00000000  \n",
       "3 -1.00000000 -1.00000000 -1.00000000 -1.00000000  \n",
       "4 -1.00000000 -1.00000000 -1.00000000 -1.00000000  \n",
       "5 -1.00000000 -1.00000000 -1.00000000 -1.00000000  \n",
       "6 -1.00000000 -1.00000000 -1.00000000 -1.00000000  \n",
       "7 -1.00000000 -1.00000000 -1.00000000 -1.00000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_coor_df(Polygon_new_update, N_P, N_C):\n",
    "    ##\n",
    "    # make each polygon's coordinates start from the left top point and sort clockwise\n",
    "    ##\n",
    "    Polygon_new_coor=[] \n",
    "    for i in range(len(Polygon_new_update)):\n",
    "        if is_clockwise(Polygon_new_update[i]):\n",
    "            Temp_polygon=convert_to_clockwise(Polygon_new_update[i])\n",
    "        else: \n",
    "            Temp_polygon=Polygon_new_update[i]\n",
    "        \n",
    "        Polygon_new_coor.append(reorder_vertices(Temp_polygon))\n",
    "      \n",
    "    #print(Polygon_new_coor)\n",
    "    \n",
    "    ##\n",
    "    # sort the polygons by their first point (first sort by time in ascending, then by space in descending)\n",
    "    ##\n",
    "    first_point=[]\n",
    "    for i in range(len(Polygon_new_coor)):\n",
    "        first_point.append(Polygon_new_coor[i][0])\n",
    "    #print(first_point)\n",
    "    # Sort by the first element of each tuple in ascending order, and by the second element in descending order\n",
    "    sorted_indices = sorted(enumerate(first_point), key=lambda x: (x[1][0], -x[1][1]))\n",
    "    # Extract just the indices from the sorted list\n",
    "    sorted_indices = [index for index, tuple in sorted_indices]\n",
    "    Polygon_sorted_coor=[]\n",
    "    for jj in sorted_indices:\n",
    "        Polygon_sorted_coor.append(Polygon_new_coor[jj])\n",
    "\n",
    "    Polygon_feature_df = pd.DataFrame()\n",
    "    for ii in range(len(Polygon_sorted_coor)):\n",
    "        flat_list = [item for tup in Polygon_sorted_coor[ii] for item in tup]\n",
    "        Polygon_feature_df= pd.concat([Polygon_feature_df, pd.DataFrame([flat_list])], ignore_index=True)  \n",
    "        \n",
    "    ##\n",
    "    # fixed size: fixed number of vertices, fixed number of polygons\n",
    "    ##\n",
    "    new_rows = range(N_P)\n",
    "    new_columns = [i for i in range(N_C*2)]\n",
    "    df_poly_extended = Polygon_feature_df.reindex(index=new_rows, columns=new_columns)\n",
    "    df_poly_extended = df_poly_extended.fillna(-1)\n",
    "        \n",
    "    return df_poly_extended,sorted_indices\n",
    "\n",
    "df_poly_extended,sorted_indices = generate_coor_df(Polygon_new_update,8,8)\n",
    "print(sorted_indices)\n",
    "df_poly_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a2b35af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 9, 6, 8], [1, 8, 7], [7, 8, 6, 5], [5, 6, 9, 4, 0], [0, 4, 3]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def first_index_of_minus_one(row,N_C):\n",
    "    return row[row == -1].index[0] if -1 in row.values else 2*N_C\n",
    "\n",
    "#first_indices_of_minus_one = df_poly_extended.apply(lambda row: first_index_of_minus_one(row, 8), axis=1)\n",
    "\n",
    "#print(first_indices_of_minus_one)\n",
    "\n",
    "def clockwise_and_sorted(df_poly_extended,sorted_indices,nodes,N_C):\n",
    "    first_indices_of_minus_one = df_poly_extended.apply(lambda row: first_index_of_minus_one(row, N_C), axis=1)\n",
    "    clockwise_sorted_cycles=[]\n",
    "    for i in range(len(sorted_indices)):\n",
    "        clockwise_cycle=[]\n",
    "        for j in range(first_indices_of_minus_one[i]):\n",
    "            if j%2==0:\n",
    "                x_coor=df_poly_extended[j][i]\n",
    "            else:\n",
    "                y_coor=df_poly_extended[j][i]\n",
    "                p_temp=(x_coor,y_coor)\n",
    "                clockwise_cycle.append(nodes.index(p_temp))\n",
    "\n",
    "        clockwise_sorted_cycles.append(clockwise_cycle)\n",
    "    return clockwise_sorted_cycles\n",
    "\n",
    "CS_cycles=clockwise_and_sorted(df_poly_extended,sorted_indices,nodes,8)\n",
    "CS_cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b86b203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 8, 6, 9, 2], [1, 8, 7], [5, 7, 8, 6], [0, 5, 6, 9, 4], [0, 3, 4]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>1.00000000</td>\n",
       "      <td>0.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5  \\\n",
       "0  0.00000000  1.00000000  1.00000000  1.00000000  0.00000000 -1.00000000   \n",
       "1  1.00000000  0.00000000  1.00000000  0.00000000  0.00000000 -1.00000000   \n",
       "2  1.00000000  1.00000000  0.00000000  1.00000000  0.00000000 -1.00000000   \n",
       "3  1.00000000  0.00000000  1.00000000  0.00000000  1.00000000 -1.00000000   \n",
       "4  0.00000000  0.00000000  0.00000000  1.00000000  0.00000000 -1.00000000   \n",
       "5 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000   \n",
       "6 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000 -1.00000000   \n",
       "\n",
       "            6  \n",
       "0 -1.00000000  \n",
       "1 -1.00000000  \n",
       "2 -1.00000000  \n",
       "3 -1.00000000  \n",
       "4 -1.00000000  \n",
       "5 -1.00000000  \n",
       "6 -1.00000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_edge_shared(cycle_1,cycle_2):\n",
    "    shared_elements = set(cycle_1) & set(cycle_2)\n",
    "    num_shared_elements = len(shared_elements)\n",
    "    if num_shared_elements>=2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def generate_connec_df(cycles_new_update,sorted_indices,N_P):\n",
    "    cycles_sorted=[]\n",
    "    for jj in sorted_indices:\n",
    "        cycles_sorted.append(cycles_new_update[jj])\n",
    "    #print(cycles_sorted)\n",
    "\n",
    "    connectivity=np.zeros((len(cycles_sorted),len(cycles_sorted)))\n",
    "    for k in range(len(cycles_sorted)-1):\n",
    "        for kk in range(k+1,len(cycles_sorted)):\n",
    "            connectivity[k][kk]=is_edge_shared(cycles_sorted[k],cycles_sorted[kk])\n",
    "            connectivity[kk][k]=is_edge_shared(cycles_sorted[k],cycles_sorted[kk])\n",
    "    connectivity_df = pd.DataFrame(connectivity) \n",
    "    \n",
    "    ##\n",
    "    # fixed size: fixed number of polygons\n",
    "    ##\n",
    "    new_rows = range(N_P)\n",
    "    new_columns = [i for i in range(N_P)]\n",
    "    df_connect_extended = connectivity_df.reindex(index=new_rows, columns=new_columns)\n",
    "    df_connect_extended = df_connect_extended.fillna(-1)\n",
    "    \n",
    "    return df_connect_extended,cycles_sorted\n",
    "\n",
    "df_connect_extended,cycles_sorted=generate_connec_df(cycles_new_update,sorted_indices,7)\n",
    "print(cycles_sorted)\n",
    "df_connect_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cc4ec10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>den</th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.00000000</td>\n",
       "      <td>900.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.00000000</td>\n",
       "      <td>1800.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.00000000</td>\n",
       "      <td>2400.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.00000000</td>\n",
       "      <td>3000.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.00000000</td>\n",
       "      <td>2400.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.00000000</td>\n",
       "      <td>-1.00000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           den          flow\n",
       "0 150.00000000  900.00000000\n",
       "1  30.00000000 1800.00000000\n",
       "2  40.00000000 2400.00000000\n",
       "3  50.00000000 3000.00000000\n",
       "4  40.00000000 2400.00000000\n",
       "5  -1.00000000   -1.00000000\n",
       "6  -1.00000000   -1.00000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_denflow_df(CS_cycles,SWL_df,nodes,N_P):\n",
    "    Polygon_density=[]\n",
    "    Polygon_flow=[]\n",
    "    ##\n",
    "    # generate edge_within: store edges within the sw diagram. e,g, [[0, 4], [5, 6], [7, 8], [1, 8], [8, 6], [6, 9]]\n",
    "    ##\n",
    "    nodes_s_index=[]\n",
    "    nodes_e_index=[]\n",
    "    edge_within=[]\n",
    "    for i in range(len(SWL_df)):\n",
    "        s_p=(SWL_df.iloc[i]['ini_t'],SWL_df.iloc[i]['ini_x'])\n",
    "        e_p=(SWL_df.iloc[i]['end_t'],SWL_df.iloc[i]['end_x'])\n",
    "        #print(s_p,e_p)\n",
    "        #print(nodes.index(s_p),nodes.index(e_p))\n",
    "        nodes_s_index.append(nodes.index(s_p))\n",
    "        nodes_e_index.append(nodes.index(e_p))\n",
    "        edge_within.append([nodes.index(s_p),nodes.index(e_p)])\n",
    "    withinedge_tuples = [tuple(sublist) for sublist in edge_within]\n",
    "    #print(\"withinedge_tuples\",withinedge_tuples)\n",
    "    #print(\"oooooooooooooooooooooooooooooooooooooo\")\n",
    "\n",
    "    for i in range(len(CS_cycles)):\n",
    "        density_pool=[]\n",
    "        flow_pool=[]\n",
    "        Edges_temp_set=[]\n",
    "        for j in range(len(CS_cycles[i])-1):\n",
    "            Edges_temp_set.append([CS_cycles[i][j],CS_cycles[i][j+1]])\n",
    "        Edges_temp_set.append([CS_cycles[i][-1],CS_cycles[i][0]])\n",
    "        #print(Edges_temp_set)\n",
    "        #print(\"--------------\")\n",
    "        a_tuples_set = set(tuple(sublist) for sublist in Edges_temp_set)\n",
    "        #print(a_tuples_set)\n",
    "        for index, sublist in enumerate(withinedge_tuples):\n",
    "            for ind, sub in enumerate(a_tuples_set):\n",
    "                if sublist[0]==sub[0] and sublist[1]==sub[1]:\n",
    "                    #print(\"yes\",sub)\n",
    "                    density_pool.append(SWL_df.iloc[index]['uk'])\n",
    "                    flow_pool.append(SWL_df.iloc[index]['uq'])\n",
    "                elif sublist[0]==sub[1] and sublist[1]==sub[0]:\n",
    "                    #print(\"reverse\",sub)\n",
    "                    density_pool.append(SWL_df.iloc[index]['dk'])\n",
    "                    flow_pool.append(SWL_df.iloc[index]['dq'])\n",
    "        #print(\"density pool\",density_pool)\n",
    "        #print(\"flow pool\",flow_pool)\n",
    "        Polygon_density.append(max(density_pool, key=density_pool.count))    \n",
    "        Polygon_flow.append(max(flow_pool, key=flow_pool.count)) \n",
    "    \n",
    "    den_flow_df = pd.DataFrame({'den': Polygon_density, 'flow': Polygon_flow}) \n",
    "\n",
    "    ##\n",
    "    # fixed size: fixed number of polygons\n",
    "    ##\n",
    "    new_rows = range(N_P)\n",
    "    df_kq_extended = den_flow_df.reindex(index=new_rows)\n",
    "    df_kq_extended = df_kq_extended.fillna(-1)\n",
    "    return df_kq_extended\n",
    "\n",
    "df_kq_extended=generate_denflow_df(CS_cycles,SWL_f,nodes,7)\n",
    "df_kq_extended\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21f0f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poly_encoding(t_0, t_e, L, SWL_df, N_P, N_C):\n",
    "    nodes = get_nodes(t_0,t_e,L,SWL_df)\n",
    "    #print(\"------\")\n",
    "    #print(nodes)\n",
    "    edges = get_edges(t_0,t_e,L,SWL_df,nodes)\n",
    "    #print(\"edge\", edges)\n",
    "    #print(\"------\")\n",
    "    cycles_all=[]\n",
    "    #print(cycles_all)\n",
    "    cycles_all = generate_cycles(edges)\n",
    "    #print(\"cycles\",cycles_all)\n",
    "    #print(\"------\")\n",
    "    Polygon_new_update, cycles_new_update= minimal_cycle(cycles_all, nodes)\n",
    "    #print(\"P_cycles\",Polygon_new_update)\n",
    "    #print(\"------\")\n",
    "    #print(\"I_CYCLES\",cycles_new_update)\n",
    "    #print(\"------\")\n",
    "    \n",
    "    # generate dataframe store polygon coordinates, connectivity between polygons, and traffic state information \n",
    "    df_poly_extended,sorted_indices = generate_coor_df(Polygon_new_update,N_P,N_C)\n",
    "    CS_cycles=clockwise_and_sorted(df_poly_extended,sorted_indices,nodes,N_C)\n",
    "    df_connect_extended,cycles_sorted=generate_connec_df(cycles_new_update,sorted_indices,N_P)\n",
    "    df_kq_extended=generate_denflow_df(CS_cycles,SWL_df,nodes,N_P)\n",
    "    #print(\"------df_poly----\")\n",
    "    #print(df_poly_extended)\n",
    "    #print(\"------df_coor----\")\n",
    "    #print(df_connect_extended)\n",
    "    #print(\"------df_kq----\")\n",
    "    #print(df_kq_extended)\n",
    "    \n",
    "    \n",
    "    # flatten above three dataframe\n",
    "    flat_poly_coor=df_poly_extended.values.flatten()\n",
    "    flat_conn=df_connect_extended.values.flatten()\n",
    "    flat_kq=df_kq_extended.values.flatten()\n",
    "    concat_feature = np.concatenate((flat_kq, flat_conn,flat_poly_coor))\n",
    "   \n",
    "    \n",
    "    return concat_feature     #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! remember to change\n",
    "    #return df_poly_extended,sorted_indices,df_kq_extended\n",
    "\n",
    "#concat_feature=generate_poly_encoding(t_0, t_e, L, SWL_f, 12, 12)   \n",
    "#concat_feature\n",
    "#df_poly_extended,sorted_indices,df_kq_extended=generate_poly_encoding(t_0, t_e, L, SWL_f, 8, 8)   \n",
    "#print(df_poly_extended)\n",
    "#print(sorted_indices)\n",
    "#print(df_kq_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b315461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_feature_cornercase(t_0,t_e,L,N_P,State):\n",
    "    \n",
    "    flat_kq=np.zeros(N_P*2)\n",
    "    flat_kq[0]=State[0][0][0]\n",
    "    flat_kq[1]=State[0][0][1]\n",
    "    print(flat_kq)\n",
    "    flat_conn=np.zeros(N_P*N_P)\n",
    "    \n",
    "    flat_coor=[-1] *(N_P*2*N_P)\n",
    "    flat_coor[0]=t_0\n",
    "    flat_coor[1]=L\n",
    "    flat_coor[2]=t_e\n",
    "    flat_coor[3]=L\n",
    "    flat_coor[4]=t_e\n",
    "    flat_coor[5]=0\n",
    "    flat_coor[6]=t_0\n",
    "    flat_coor[7]=0\n",
    "    \n",
    "    concat_feature = np.concatenate((flat_kq, flat_conn,flat_coor))\n",
    "    return concat_feature "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378eec5",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84855e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load upstream and down stream data from office computer！！！\n",
    "den_2947 = pd.read_csv('concatenated_density_2947_month_5to9.csv')\n",
    "den_2958 = pd.read_csv('concatenated_density_2958_month_5to9.csv')\n",
    "den_998 = pd.read_csv('concatenated_density_998_month_5to9.csv')\n",
    "\n",
    "vol_2947 = pd.read_csv('concatenated_volume_2947_month_5to9.csv')\n",
    "vol_2958 = pd.read_csv('concatenated_volume_2958_month_5to9.csv')\n",
    "vol_998 = pd.read_csv('concatenated_volume_998_month_5to9.csv')\n",
    "\n",
    "den_2947=den_2947['0'].tolist()\n",
    "den_2958=den_2958['0'].tolist()\n",
    "den_998=den_998['0'].tolist()\n",
    "vol_2947=vol_2947['0'].tolist()\n",
    "vol_2958=vol_2958['0'].tolist()\n",
    "vol_998=vol_998['0'].tolist()\n",
    "print(len(den_2947),len(den_2958),len(den_998),len(vol_2947),len(vol_2947),len(vol_998))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd53528",
   "metadata": {},
   "source": [
    "### puzzle based encoding generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5a658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#puzzle-based encoding for 2947-2958\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "N_P = 12\n",
    "N_C = 12\n",
    "t_invl = 20/3600\n",
    "running_time=0\n",
    "Bug_flag=0\n",
    "\n",
    "for I in range(150):\n",
    "    clear_output(wait=True)\n",
    "    df_flatten_poly = pd.DataFrame()\n",
    "    print(f\"The code running time is {running_time} seconds.\")\n",
    "    start_time = time.time()\n",
    "    for ii in range(4320*I,4320*(I+1)):  # MAY 0-133920, JUNE 133920-263520, JULY 263520-397440, AUGUST 397440-531360, 531360-660960\n",
    "        print(\"DAY\",I, \"interation:\",ii)\n",
    "        #print(\"vol veh/h:\", UPstream[\"volume\"][ii]*120)\n",
    "        #print(\"den veh/mile:\", UPstream[\"occupancy\"][ii]*5280/20*0.01)  # 5280 ft=1mile, 20ft=length of car+length of detector\n",
    "        #print(\"vol veh/h:\", Downstream[\"volume\"][ii]*120)\n",
    "        #print(\"den veh/mile:\", Downstream[\"occupancy\"][ii]*5280/20*0.01)  # 5280 ft=1mile, 20ft=length of car+length of detector\n",
    "        t_0=ii*20/3600  # unit:hour\n",
    "        t_0 = round(t_0, 8)\n",
    "        t_e=t_0+20/3600 # unit:hour\n",
    "        t_e = round(t_e, 8)\n",
    "        L=0.49           # unit:mile\n",
    "        us=[den_2947[ii], vol_2947[ii]*180]      #[veh/mile, veh/h]\n",
    "        ds=[den_2958[ii], vol_2958[ii]*180]      #[veh/mile, veh/h]\n",
    "        print(\"us:\",us)\n",
    "        print(\"ds:\",ds)\n",
    "\n",
    "        if ii==0:\n",
    "            s_ini=[[2.1,120],[2.765,180]]\n",
    "            swp=[0.2]\n",
    "        elif ii==129600:\n",
    "            s_ini=[[0.0, 0], [2.379, 180]]\n",
    "            swp=[0.4203450189115721]\n",
    "        elif ii==531360:\n",
    "            s_ini=[[0.0, 0], [5.856, 360]]\n",
    "            swp=[0.3415300546398388]\n",
    "        elif ii==428762:   # bug location\n",
    "            s_ini=[[21.228, 1080], [14.457, 720], [8.784, 540]]\n",
    "            swp=[0.29537734455337405, 0.3625471531766078]\n",
    "        elif ii==494951:   # bug location\n",
    "            s_ini=[[63.318, 1440], [68.991, 1800], [31.659, 540], [17.019, 720]]\n",
    "            swp=[0.35254715317660773, 0.37501339333001915, 0.41983606556617314]\n",
    "        elif ii==658406:\n",
    "            s_ini=[[75.03, 1260], [38.979, 900]]\n",
    "            swp=[0.48999999689846935]\n",
    "        else:\n",
    "            s_ini=[]\n",
    "            s_ini=s_ini+s_endP  # need to change\n",
    "            swp=[]\n",
    "            swp=swp+sw_endP\n",
    "        for h in range(len(swp)):   # maybe I need to change the dataframe based on this\n",
    "            if 0.489999999<swp[h]<=0.49000001:\n",
    "                swp[h]=0.489    # such setting may result in bugs\n",
    "            if -0.00000001<swp[h]<0.00000001:\n",
    "                swp[h]=0.001    # such setting may result in bugs \n",
    "            if swp[h]>0.49000001:\n",
    "                print(\"DEBUG!!!!!\")\n",
    "                Bug_flag=1\n",
    "                break\n",
    "                \n",
    "        if Bug_flag==1:\n",
    "            print(\"HAHA BUG\")\n",
    "            break\n",
    "            \n",
    "                          \n",
    "        # -----------\n",
    "        differences = [swp[i+1] - swp[i] for i in range(len(swp)-1)]\n",
    "        indices_of_0 = [i for i, x in enumerate(differences) if np.abs(x)<0.00000001]\n",
    "        indices_of_0_reversed=sorted(indices_of_0, reverse=True)\n",
    "        for index in indices_of_0_reversed:\n",
    "            del swp[index]\n",
    "            del s_ini[index+1]    # maybe I need to change the dataframe based on this\n",
    "        # -----------\n",
    "\n",
    "        print(\"s_ini\", s_ini)\n",
    "        print(\"swp\",swp)\n",
    "        State, ShockwavePosition, Slopes, TS, sw_Lst, sw_endP, s_endP, Inter_P= swg1 (us, ds, s_ini, swp, t_0, t_e, L)\n",
    "        SWL_f=gen_SWL_final(ShockwavePosition,TS, Inter_P, sw_endP, Slopes, State, L)\n",
    "        #print(SWL_f)\n",
    "\n",
    "        if len(SWL_f)>0:\n",
    "            #df_poly_extended,sorted_indices,df_kq_extended=generate_poly_encoding(t_0, t_e, L, SWL_f, N_P, N_C)\n",
    "            concat_feature=generate_poly_encoding(t_0, t_e, L, SWL_f, N_P, N_C)   \n",
    "            \n",
    "        else:\n",
    "            concat_feature=concat_feature_cornercase(t_0,t_e,L,N_P,State)\n",
    "\n",
    "        if len(concat_feature)>456:\n",
    "            print(\"debug this line\")\n",
    "            break\n",
    "\n",
    "\n",
    "        df_flatten_poly  = pd.concat([df_flatten_poly, pd.DataFrame([concat_feature])],axis=0, ignore_index=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    running_time = end_time - start_time\n",
    "    \n",
    "    # for one day encoding result, save it to a file\n",
    "    if len(df_flatten_poly)==4320:\n",
    "        filename = f\"poly_new_4758/Poly_47to58_{I}.csv\"\n",
    "        df_flatten_poly.to_csv(filename, index=False)\n",
    "    else:\n",
    "        print(\"DEBUG\")\n",
    "        break    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309bdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path pattern for the CSV files\n",
    "path_pattern = 'Poly_47to58_*.csv'\n",
    "\n",
    "# Use glob to find all files matching the pattern\n",
    "file_paths = glob.glob(path_pattern)\n",
    "\n",
    "# Sort the file paths based on the numerical part of the filename\n",
    "sorted_file_paths = sorted(file_paths, key=lambda x: int(re.search(r'(\\d+)\\.csv$', x).group(1)))\n",
    "\n",
    "# Read each file into a DataFrame and store in a list\n",
    "dataframes = [pd.read_csv(file) for file in sorted_file_paths]\n",
    "\n",
    "# Concatenate all DataFrames along axis 0\n",
    "concatenated_df = pd.concat(dataframes, axis=0)\n",
    "\n",
    "# Optionally, save the concatenated DataFrame to a new CSV file\n",
    "output_file_path = 'Poly_47to58_concatenated.csv'\n",
    "concatenated_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"All files have been concatenated and saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b237756",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_na = pd.read_csv('Poly_47to58_concatenated.csv')\n",
    "check_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26dc89f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f1896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#puzzle-based encoding for 2958-998\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "N_P = 12\n",
    "N_C = 12\n",
    "t_invl = 20/3600\n",
    "running_time=0\n",
    "Bug_flag=0\n",
    "\n",
    "for I in range(150):\n",
    "    clear_output(wait=True)\n",
    "    df_flatten_poly = pd.DataFrame()\n",
    "    print(f\"The code running time is {running_time} seconds.\")\n",
    "    start_time = time.time()\n",
    "    for ii in range(4320*I,4320*(I+1)):  # MAY 0-133920, JUNE 133920-263520, JULY 263520-397440, AUGUST 397440-531360, 531360-660960\n",
    "        print(\"DAY\",I, \"interation:\",ii)\n",
    "        #print(\"vol veh/h:\", UPstream[\"volume\"][ii]*120)\n",
    "        #print(\"den veh/mile:\", UPstream[\"occupancy\"][ii]*5280/20*0.01)  # 5280 ft=1mile, 20ft=length of car+length of detector\n",
    "        #print(\"vol veh/h:\", Downstream[\"volume\"][ii]*120)\n",
    "        #print(\"den veh/mile:\", Downstream[\"occupancy\"][ii]*5280/20*0.01)  # 5280 ft=1mile, 20ft=length of car+length of detector\n",
    "        t_0=ii*20/3600  # unit:hour\n",
    "        t_0 = round(t_0, 8)\n",
    "        t_e=t_0+20/3600 # unit:hour\n",
    "        t_e = round(t_e, 8)\n",
    "        L=0.4           # unit:mile\n",
    "        us=[den_2958[ii], vol_2958[ii]*180]      #[veh/mile, veh/h]\n",
    "        ds=[den_998[ii], vol_998[ii]*180]      #[veh/mile, veh/h]\n",
    "        print(\"us:\",us)\n",
    "        print(\"ds:\",ds)\n",
    "        \n",
    "        if ii==0:\n",
    "            s_ini=[[2.765, 180], [0.0, 0]]\n",
    "            swp=[0.203200624455301]\n",
    "        elif ii==286639:\n",
    "            s_ini=[[144.753, 720], [50.691, 540], [84.546, 1080], [97.722, 1260]]\n",
    "            swp=[0.085050285980349, 0.3898404962210432, 0.399]\n",
    "        else:\n",
    "            s_ini=[]\n",
    "            s_ini=s_ini+s_endP  # need to change\n",
    "            swp=[]\n",
    "            swp=swp+sw_endP\n",
    "            \n",
    "        for h in range(len(swp)):   # maybe I need to change the dataframe based on this\n",
    "            if 0.399999999<swp[h]<=0.41000001:   #0.40000001\n",
    "                swp[h]=0.399    # such setting may result in bugs\n",
    "            if -0.00000001<swp[h]<0.00000001:\n",
    "                swp[h]=0.001    # such setting may result in bugs\n",
    "            if swp[h]>0.41000001:\n",
    "                print(\"DEBUG!!!!!\")\n",
    "                Bug_flag=1\n",
    "                break\n",
    "                \n",
    "        if Bug_flag==1:\n",
    "            print(\"HAHA BUG\")\n",
    "            break\n",
    "                          \n",
    "        # -----------\n",
    "        differences = [swp[i+1] - swp[i] for i in range(len(swp)-1)]\n",
    "        indices_of_0 = [i for i, x in enumerate(differences) if np.abs(x)<0.00000001]\n",
    "        indices_of_0_reversed=sorted(indices_of_0, reverse=True)\n",
    "        for index in indices_of_0_reversed:\n",
    "            del swp[index]\n",
    "            del s_ini[index+1]    # maybe I need to change the dataframe based on this\n",
    "        # -----------\n",
    "\n",
    "        print(\"s_ini\", s_ini)\n",
    "        print(\"swp\",swp)\n",
    "        State, ShockwavePosition, Slopes, TS, sw_Lst, sw_endP, s_endP, Inter_P= swg1 (us, ds, s_ini, swp, t_0, t_e, L)\n",
    "        SWL_f=gen_SWL_final(ShockwavePosition,TS, Inter_P, sw_endP, Slopes, State, L)\n",
    "        #print(SWL_f)\n",
    "\n",
    "        if len(SWL_f)>0:\n",
    "            #df_poly_extended,sorted_indices,df_kq_extended=generate_poly_encoding(t_0, t_e, L, SWL_f, N_P, N_C)\n",
    "            concat_feature=generate_poly_encoding(t_0, t_e, L, SWL_f, N_P, N_C)   \n",
    "            \n",
    "        else:\n",
    "            concat_feature=concat_feature_cornercase(t_0,t_e,L,N_P,State)\n",
    "\n",
    "        if len(concat_feature)>456:\n",
    "            print(\"debug this line\")\n",
    "            break\n",
    "\n",
    "\n",
    "        df_flatten_poly  = pd.concat([df_flatten_poly, pd.DataFrame([concat_feature])],axis=0, ignore_index=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    running_time = end_time - start_time\n",
    "    \n",
    "    if len(df_flatten_poly)==4320:\n",
    "        filename = f\"Poly_58to98_{I}.csv\"\n",
    "        df_flatten_poly.to_csv(filename, index=False)\n",
    "    else:\n",
    "        print(\"DEBUG\")\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path pattern for the CSV files\n",
    "path_pattern = 'Poly_58to98_*.csv'\n",
    "\n",
    "# Use glob to find all files matching the pattern\n",
    "file_paths = glob.glob(path_pattern)\n",
    "\n",
    "# Sort the file paths based on the numerical part of the filename\n",
    "sorted_file_paths = sorted(file_paths, key=lambda x: int(re.search(r'(\\d+)\\.csv$', x).group(1)))\n",
    "\n",
    "# Read each file into a DataFrame and store in a list\n",
    "dataframes = [pd.read_csv(file) for file in sorted_file_paths]\n",
    "\n",
    "# Concatenate all DataFrames along axis 0\n",
    "concatenated_df = pd.concat(dataframes, axis=0)\n",
    "\n",
    "# Optionally, save the concatenated DataFrame to a new CSV file\n",
    "output_file_path = 'Poly_58to98_concatenated.csv'\n",
    "concatenated_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"All files have been concatenated and saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91037da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9694cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_58_98 = pd.read_csv('Poly_58to98_concatenated.csv')\n",
    "\n",
    "copied_58_98 = poly_58_98.copy()\n",
    "check_df1 = copied_58_98[:4320]\n",
    "\n",
    "\n",
    "rows_to_change = poly_58_98.iloc[:, 2:167].eq(0).all(axis=1)\n",
    "poly_58_98.loc[rows_to_change, poly_58_98.columns[2:24]] = -1\n",
    "poly_58_98.loc[rows_to_change, poly_58_98.columns[25:168]] = -1\n",
    "######### change the x coordinates, let all SW diagram start from time 0.\n",
    "# Identify the first x coordinates colum\n",
    "first_xcoor_column = poly_58_98.iloc[:, 168]\n",
    "odd_columns_indices = [i for i in range(170, poly_58_98.shape[1], 2)]  # Start from Col5\n",
    "# Subtract the third column from each selected odd-indexed column only where the element is not -1\n",
    "for idx in odd_columns_indices:\n",
    "    poly_58_98.iloc[:, idx] = poly_58_98.iloc[:, idx].where(poly_58_98.iloc[:, idx] == -1, poly_58_98.iloc[:, idx] - first_xcoor_column)\n",
    "# Update Col3 to be zero since it subtracts from itself\n",
    "poly_58_98['168'] = 0\n",
    "\n",
    "# Get the column indices for the specified ranges\n",
    "cols_to_keep = list(range(0, 14)) + list(range(24, 31)) + list(range(36, 43)) + list(range(48, 55)) +\\\n",
    "               list(range(60, 67)) + list(range(72, 79)) + list(range(84, 91)) + list(range(96, 103)) +\\\n",
    "               list(range(168, 182)) + list(range(192, 206)) + list(range(216, 230)) + list(range(240, 254))+\\\n",
    "               list(range(264, 278)) + list(range(288, 302)) + list(range(312, 326))\n",
    "                   \n",
    "\n",
    "poly_58_98= poly_58_98.iloc[:, cols_to_keep]\n",
    "\n",
    "#poly_58_98.replace(-1, 0, inplace=True) # change -1 in dataframe to 0\n",
    "\n",
    "check_df2 = poly_58_98[:4320]\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------\n",
    "poly_47_58 = pd.read_csv('Poly_47to58_concatenated.csv')\n",
    "\n",
    "copied_47_58 = poly_47_58.copy()\n",
    "check_df1a = copied_47_58[:4320]\n",
    "\n",
    "\n",
    "rows_to_change1 = poly_47_58.iloc[:, 2:167].eq(0).all(axis=1)\n",
    "poly_47_58.loc[rows_to_change1, poly_47_58.columns[2:24]] = -1\n",
    "poly_47_58.loc[rows_to_change1, poly_47_58.columns[25:168]] = -1\n",
    "######### change the x coordinates, let all SW diagram start from time 0.\n",
    "# Identify the first x coordinates colum\n",
    "first_xcoor_column = poly_47_58.iloc[:, 168]\n",
    "odd_columns_indicesa = [i for i in range(170, poly_47_58.shape[1], 2)]  # Start from Col5\n",
    "# Subtract the third column from each selected odd-indexed column only where the element is not -1\n",
    "for idx in odd_columns_indicesa:\n",
    "    poly_47_58.iloc[:, idx] = poly_47_58.iloc[:, idx].where(poly_47_58.iloc[:, idx] == -1, poly_47_58.iloc[:, idx] - first_xcoor_column)\n",
    "# Update Col3 to be zero since it subtracts from itself\n",
    "poly_47_58['168'] = 0\n",
    "\n",
    "poly_47_58= poly_47_58.iloc[:, cols_to_keep]\n",
    "\n",
    "#poly_47_58.replace(-1, 0, inplace=True) # change -1 in dataframe to 0\n",
    "\n",
    "# Generate new column names with 'a' appended\n",
    "new_column_names = {str(col): str(col) + 'a' for col in poly_47_58.columns}\n",
    "# Rename the columns\n",
    "poly_47_58.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "check_df2a = poly_47_58[:4320]\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "concat_poly = pd.concat([poly_58_98.iloc[:, :14], poly_47_58.iloc[:, :14], poly_58_98.iloc[:, 14:14+49], poly_47_58.iloc[:, 14:14+49], poly_58_98.iloc[:, 14+49:], poly_47_58.iloc[:, 14+49:]], axis=1)\n",
    "check_df_final=concat_poly[:4320]\n",
    "concat_poly.to_csv(\"Poly_47to98_concatenated_new.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9620ec3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1866b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978df70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2bc0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915085d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88877552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
